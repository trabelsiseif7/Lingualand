{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\n!pip install bitsandbytes","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-02T23:28:26.187930Z","iopub.execute_input":"2023-05-02T23:28:26.188197Z","iopub.status.idle":"2023-05-02T23:28:54.057877Z","shell.execute_reply.started":"2023-05-02T23:28:26.188170Z","shell.execute_reply":"2023-05-02T23:28:54.056711Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.27.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting bitsandbytes\n  Downloading bitsandbytes-0.38.1-py3-none-any.whl (104.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.38.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import transformers\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch.cuda.amp import custom_fwd, custom_bwd \n\nfrom bitsandbytes.functional import quantize_blockwise, dequantize_blockwise\n\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:28:54.060402Z","iopub.execute_input":"2023-05-02T23:28:54.061928Z","iopub.status.idle":"2023-05-02T23:29:00.647569Z","shell.execute_reply.started":"2023-05-02T23:28:54.061884Z","shell.execute_reply":"2023-05-02T23:29:00.646474Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\n===================================BUG REPORT===================================\nWelcome to bitsandbytes. For bug reports, please run\n\npython -m bitsandbytes\n\n and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n================================================================================\nbin /opt/conda/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so\nCUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\nCUDA SETUP: Highest compute capability among GPUs detected: 7.5\nCUDA SETUP: Detected CUDA version 113\nCUDA SETUP: Loading binary /opt/conda/lib/python3.7/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/lib/x86_64-linux-gnu'), PosixPath('/usr/local/cuda/lib'), PosixPath('/usr/local/nvidia/lib')}\n  warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"class FrozenBNBLinear(nn.Module):\n    def __init__(self, weight, absmax, code, bias=None):\n        assert isinstance(bias, nn.Parameter) or bias is None\n        super().__init__()\n        self.out_features, self.in_features = weight.shape\n        self.register_buffer(\"weight\", weight.requires_grad_(False))\n        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n        self.register_buffer(\"code\", code.requires_grad_(False))\n        self.adapter = None\n        self.bias = bias\n \n    def forward(self, input):\n        output = DequantizeAndLinear.apply(input, self.weight, self.absmax, self.code, self.bias)\n        if self.adapter:\n            output_cloned = torch.clone(output + self.adapter(input))\n            return output_cloned\n        else :\n            return output\n \n    @classmethod\n    def from_linear(cls, linear: nn.Linear) -> \"FrozenBNBLinear\":\n        weights_int8, state = quantize_blockise_lowmemory(linear.weight)\n        return cls(weights_int8, *state, linear.bias)\n \n    def __repr__(self):\n        return f\"{self.__class__.__name__}({self.in_features}, {self.out_features})\"\n \n \nclass DequantizeAndLinear(torch.autograd.Function): \n    @staticmethod\n    @custom_fwd\n    def forward(ctx, input: torch.Tensor, weights_quantized: torch.ByteTensor,\n                absmax: torch.FloatTensor, code: torch.FloatTensor, bias: torch.FloatTensor):\n        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n        ctx.save_for_backward(input, weights_quantized, absmax, code)\n        ctx._has_bias = bias is not None\n        return F.linear(input, weights_deq, bias)\n \n    @staticmethod\n    @custom_bwd\n    def backward(ctx, grad_output: torch.Tensor):\n        assert not ctx.needs_input_grad[1] and not ctx.needs_input_grad[2] and not ctx.needs_input_grad[3]\n        input, weights_quantized, absmax, code = ctx.saved_tensors\n        # grad_output: [*batch, out_features]\n        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n        grad_input = grad_output @ weights_deq\n        grad_bias = grad_output.flatten(0, -2).sum(dim=0) if ctx._has_bias else None\n        return grad_input, None, None, None, grad_bias\n \n \nclass FrozenBNBEmbedding(nn.Module):\n    def __init__(self, weight, absmax, code):\n        super().__init__()\n        self.num_embeddings, self.embedding_dim = weight.shape\n        self.register_buffer(\"weight\", weight.requires_grad_(False))\n        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n        self.register_buffer(\"code\", code.requires_grad_(False))\n        self.adapter = None\n \n    def forward(self, input, **kwargs):\n        with torch.no_grad():\n            # note: both quantuized weights and input indices are *not* differentiable\n            weight_deq = dequantize_blockwise(self.weight, absmax=self.absmax, code=self.code)\n            output = F.embedding(input, weight_deq, **kwargs)\n        if self.adapter:\n            \n            output_cloned = torch.clone(output + self.adapter(input))\n            return output_cloned\n        else :\n            return output \n \n    @classmethod\n    def from_embedding(cls, embedding: nn.Embedding) -> \"FrozenBNBEmbedding\":\n        weights_int8, state = quantize_blockise_lowmemory(embedding.weight)\n        return cls(weights_int8, *state)\n \n    def __repr__(self):\n        return f\"{self.__class__.__name__}({self.num_embeddings}, {self.embedding_dim})\"\n \n \ndef quantize_blockise_lowmemory(matrix: torch.Tensor, chunk_size: int = 2 ** 20):\n    assert chunk_size % 4096 == 0\n    code = None\n    chunks = []\n    absmaxes = []\n    flat_tensor = matrix.view(-1)\n    for i in range((matrix.numel() - 1) // chunk_size + 1):\n        input_chunk = flat_tensor[i * chunk_size: (i + 1) * chunk_size].clone()\n        quantized_chunk, (absmax_chunk, code) = quantize_blockwise(input_chunk, code=code)\n        chunks.append(quantized_chunk)\n        absmaxes.append(absmax_chunk)\n \n    matrix_i8 = torch.cat(chunks).reshape_as(matrix)\n    absmax = torch.cat(absmaxes)\n    return matrix_i8, (absmax, code)\n \n \ndef convert_to_int8(model):\n    \"\"\"Convert linear and embedding modules to 8-bit with optional adapters\"\"\"\n    for module in list(model.modules()):\n        for name, child in module.named_children():\n            if isinstance(child, nn.Linear):\n                print(name, child)\n                setattr( \n                    module,\n                    name,\n                    FrozenBNBLinear(\n                        weight=torch.zeros(child.out_features, child.in_features, dtype=torch.uint8),\n                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n                        code=torch.zeros(256),\n                        bias=child.bias,\n                    ),\n                )\n            elif isinstance(child, nn.Embedding):\n                setattr(\n                    module,\n                    name,\n                    FrozenBNBEmbedding(\n                        weight=torch.zeros(child.num_embeddings, child.embedding_dim, dtype=torch.uint8),\n                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n                        code=torch.zeros(256),\n                    )\n                )\n     ","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:29:00.650279Z","iopub.execute_input":"2023-05-02T23:29:00.650953Z","iopub.status.idle":"2023-05-02T23:29:00.677489Z","shell.execute_reply.started":"2023-05-02T23:29:00.650912Z","shell.execute_reply":"2023-05-02T23:29:00.675686Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class GPTJBlock(transformers.models.gptj.modeling_gptj.GPTJBlock):\n    def __init__(self, config):\n        super().__init__(config)\n\n        convert_to_int8(self.attn)\n        convert_to_int8(self.mlp)\n\n\nclass GPTJModel(transformers.models.gptj.modeling_gptj.GPTJModel):\n    def __init__(self, config):\n        super().__init__(config)\n        convert_to_int8(self)\n        \n\nclass GPTJForCausalLM(transformers.models.gptj.modeling_gptj.GPTJForCausalLM):\n    def __init__(self, config):\n        super().__init__(config)\n        convert_to_int8(self)\n\n\ntransformers.models.gptj.modeling_gptj.GPTJBlock = GPTJBlock  # monkey-patch GPT-J","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:29:00.680348Z","iopub.execute_input":"2023-05-02T23:29:00.680834Z","iopub.status.idle":"2023-05-02T23:29:03.894318Z","shell.execute_reply.started":"2023-05-02T23:29:00.680797Z","shell.execute_reply":"2023-05-02T23:29:03.893164Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"config = transformers.GPTJConfig.from_pretrained(\"EleutherAI/gpt-j-6B\")\ntokenizer = transformers.AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:29:03.896222Z","iopub.execute_input":"2023-05-02T23:29:03.896563Z","iopub.status.idle":"2023-05-02T23:29:06.417143Z","shell.execute_reply.started":"2023-05-02T23:29:03.896531Z","shell.execute_reply":"2023-05-02T23:29:06.416075Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/930 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0df29e5e91543f88515d85cee54891c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47cecc3298144a3b8824283f33cf2ed3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9196d194163340faa4a778970ef9d812"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c804029360d4a9098978739f7fff584"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.37M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38f1f80de8c344e6ab4efc3f400ded82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)in/added_tokens.json:   0%|          | 0.00/4.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f593346948e49479641e714e71ffd6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e269bc0f6bef4b099c3765bffd24bd70"}},"metadata":{}}]},{"cell_type":"code","source":"gpt = GPTJForCausalLM.from_pretrained(\"hivemind/gpt-j-6B-8bit\", low_cpu_mem_usage=True)\n\nif torch.cuda.is_available():  \n    dev = \"cuda:0\" \nelse:  \n    dev = \"cpu\"  \ndevice = torch.device(dev)  \n\ngpt.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:29:06.418624Z","iopub.execute_input":"2023-05-02T23:29:06.419087Z","iopub.status.idle":"2023-05-02T23:30:51.992578Z","shell.execute_reply.started":"2023-05-02T23:29:06.419047Z","shell.execute_reply":"2023-05-02T23:30:51.989715Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f815a359b294525b96619084c8a34c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/6.18G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19a09409c83e45f19dac2f5a0b33dacb"}},"metadata":{}},{"name":"stdout","text":"k_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nlm_head Linear(in_features=4096, out_features=50400, bias=True)\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"GPTJForCausalLM(\n  (transformer): GPTJModel(\n    (wte): FrozenBNBEmbedding(50400, 4096)\n    (drop): Dropout(p=0.0, inplace=False)\n    (h): ModuleList(\n      (0): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (2): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (3): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (4): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (5): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (6): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (7): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (8): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (9): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (10): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (11): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (12): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (13): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (14): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (15): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (16): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (17): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (18): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (19): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (20): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (21): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (22): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (23): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (24): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (25): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (26): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (27): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): FrozenBNBLinear(4096, 50400)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def add_adapters(model, adapter_dim=4, p = 0.1):\n    assert adapter_dim > 0\n\n    for name, module in model.named_modules():\n      if isinstance(module, FrozenBNBLinear):\n          if \"attn\" in name or \"mlp\" in name or \"head\" in name:\n              print(\"Adding adapter to\", name)\n              module.adapter = nn.Sequential(\n                nn.Linear(module.in_features, adapter_dim, bias=False),\n                nn.Dropout(p=p),\n                nn.Linear(adapter_dim, module.out_features, bias=False),\n            )\n              print(\"Initializing\", name)\n              nn.init.zeros_(module.adapter[2].weight)\n\n          else:\n              print(\"Not adding adapter to\", name)\n      elif isinstance(module, FrozenBNBEmbedding):\n          print(\"Adding adapter to\", name)\n          module.adapter = nn.Sequential(\n                nn.Embedding(module.num_embeddings, adapter_dim),\n                nn.Dropout(p=p),\n                nn.Linear(adapter_dim, module.embedding_dim, bias=False),\n            )\n          print(\"Initializing\", name)\n          nn.init.zeros_(module.adapter[2].weight)\n\nadd_adapters(gpt)\ngpt.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:30:51.997046Z","iopub.execute_input":"2023-05-02T23:30:51.997344Z","iopub.status.idle":"2023-05-02T23:30:52.164101Z","shell.execute_reply.started":"2023-05-02T23:30:51.997317Z","shell.execute_reply":"2023-05-02T23:30:52.163063Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Adding adapter to transformer.wte\nInitializing transformer.wte\nAdding adapter to transformer.h.0.attn.k_proj\nInitializing transformer.h.0.attn.k_proj\nAdding adapter to transformer.h.0.attn.v_proj\nInitializing transformer.h.0.attn.v_proj\nAdding adapter to transformer.h.0.attn.q_proj\nInitializing transformer.h.0.attn.q_proj\nAdding adapter to transformer.h.0.attn.out_proj\nInitializing transformer.h.0.attn.out_proj\nAdding adapter to transformer.h.0.mlp.fc_in\nInitializing transformer.h.0.mlp.fc_in\nAdding adapter to transformer.h.0.mlp.fc_out\nInitializing transformer.h.0.mlp.fc_out\nAdding adapter to transformer.h.1.attn.k_proj\nInitializing transformer.h.1.attn.k_proj\nAdding adapter to transformer.h.1.attn.v_proj\nInitializing transformer.h.1.attn.v_proj\nAdding adapter to transformer.h.1.attn.q_proj\nInitializing transformer.h.1.attn.q_proj\nAdding adapter to transformer.h.1.attn.out_proj\nInitializing transformer.h.1.attn.out_proj\nAdding adapter to transformer.h.1.mlp.fc_in\nInitializing transformer.h.1.mlp.fc_in\nAdding adapter to transformer.h.1.mlp.fc_out\nInitializing transformer.h.1.mlp.fc_out\nAdding adapter to transformer.h.2.attn.k_proj\nInitializing transformer.h.2.attn.k_proj\nAdding adapter to transformer.h.2.attn.v_proj\nInitializing transformer.h.2.attn.v_proj\nAdding adapter to transformer.h.2.attn.q_proj\nInitializing transformer.h.2.attn.q_proj\nAdding adapter to transformer.h.2.attn.out_proj\nInitializing transformer.h.2.attn.out_proj\nAdding adapter to transformer.h.2.mlp.fc_in\nInitializing transformer.h.2.mlp.fc_in\nAdding adapter to transformer.h.2.mlp.fc_out\nInitializing transformer.h.2.mlp.fc_out\nAdding adapter to transformer.h.3.attn.k_proj\nInitializing transformer.h.3.attn.k_proj\nAdding adapter to transformer.h.3.attn.v_proj\nInitializing transformer.h.3.attn.v_proj\nAdding adapter to transformer.h.3.attn.q_proj\nInitializing transformer.h.3.attn.q_proj\nAdding adapter to transformer.h.3.attn.out_proj\nInitializing transformer.h.3.attn.out_proj\nAdding adapter to transformer.h.3.mlp.fc_in\nInitializing transformer.h.3.mlp.fc_in\nAdding adapter to transformer.h.3.mlp.fc_out\nInitializing transformer.h.3.mlp.fc_out\nAdding adapter to transformer.h.4.attn.k_proj\nInitializing transformer.h.4.attn.k_proj\nAdding adapter to transformer.h.4.attn.v_proj\nInitializing transformer.h.4.attn.v_proj\nAdding adapter to transformer.h.4.attn.q_proj\nInitializing transformer.h.4.attn.q_proj\nAdding adapter to transformer.h.4.attn.out_proj\nInitializing transformer.h.4.attn.out_proj\nAdding adapter to transformer.h.4.mlp.fc_in\nInitializing transformer.h.4.mlp.fc_in\nAdding adapter to transformer.h.4.mlp.fc_out\nInitializing transformer.h.4.mlp.fc_out\nAdding adapter to transformer.h.5.attn.k_proj\nInitializing transformer.h.5.attn.k_proj\nAdding adapter to transformer.h.5.attn.v_proj\nInitializing transformer.h.5.attn.v_proj\nAdding adapter to transformer.h.5.attn.q_proj\nInitializing transformer.h.5.attn.q_proj\nAdding adapter to transformer.h.5.attn.out_proj\nInitializing transformer.h.5.attn.out_proj\nAdding adapter to transformer.h.5.mlp.fc_in\nInitializing transformer.h.5.mlp.fc_in\nAdding adapter to transformer.h.5.mlp.fc_out\nInitializing transformer.h.5.mlp.fc_out\nAdding adapter to transformer.h.6.attn.k_proj\nInitializing transformer.h.6.attn.k_proj\nAdding adapter to transformer.h.6.attn.v_proj\nInitializing transformer.h.6.attn.v_proj\nAdding adapter to transformer.h.6.attn.q_proj\nInitializing transformer.h.6.attn.q_proj\nAdding adapter to transformer.h.6.attn.out_proj\nInitializing transformer.h.6.attn.out_proj\nAdding adapter to transformer.h.6.mlp.fc_in\nInitializing transformer.h.6.mlp.fc_in\nAdding adapter to transformer.h.6.mlp.fc_out\nInitializing transformer.h.6.mlp.fc_out\nAdding adapter to transformer.h.7.attn.k_proj\nInitializing transformer.h.7.attn.k_proj\nAdding adapter to transformer.h.7.attn.v_proj\nInitializing transformer.h.7.attn.v_proj\nAdding adapter to transformer.h.7.attn.q_proj\nInitializing transformer.h.7.attn.q_proj\nAdding adapter to transformer.h.7.attn.out_proj\nInitializing transformer.h.7.attn.out_proj\nAdding adapter to transformer.h.7.mlp.fc_in\nInitializing transformer.h.7.mlp.fc_in\nAdding adapter to transformer.h.7.mlp.fc_out\nInitializing transformer.h.7.mlp.fc_out\nAdding adapter to transformer.h.8.attn.k_proj\nInitializing transformer.h.8.attn.k_proj\nAdding adapter to transformer.h.8.attn.v_proj\nInitializing transformer.h.8.attn.v_proj\nAdding adapter to transformer.h.8.attn.q_proj\nInitializing transformer.h.8.attn.q_proj\nAdding adapter to transformer.h.8.attn.out_proj\nInitializing transformer.h.8.attn.out_proj\nAdding adapter to transformer.h.8.mlp.fc_in\nInitializing transformer.h.8.mlp.fc_in\nAdding adapter to transformer.h.8.mlp.fc_out\nInitializing transformer.h.8.mlp.fc_out\nAdding adapter to transformer.h.9.attn.k_proj\nInitializing transformer.h.9.attn.k_proj\nAdding adapter to transformer.h.9.attn.v_proj\nInitializing transformer.h.9.attn.v_proj\nAdding adapter to transformer.h.9.attn.q_proj\nInitializing transformer.h.9.attn.q_proj\nAdding adapter to transformer.h.9.attn.out_proj\nInitializing transformer.h.9.attn.out_proj\nAdding adapter to transformer.h.9.mlp.fc_in\nInitializing transformer.h.9.mlp.fc_in\nAdding adapter to transformer.h.9.mlp.fc_out\nInitializing transformer.h.9.mlp.fc_out\nAdding adapter to transformer.h.10.attn.k_proj\nInitializing transformer.h.10.attn.k_proj\nAdding adapter to transformer.h.10.attn.v_proj\nInitializing transformer.h.10.attn.v_proj\nAdding adapter to transformer.h.10.attn.q_proj\nInitializing transformer.h.10.attn.q_proj\nAdding adapter to transformer.h.10.attn.out_proj\nInitializing transformer.h.10.attn.out_proj\nAdding adapter to transformer.h.10.mlp.fc_in\nInitializing transformer.h.10.mlp.fc_in\nAdding adapter to transformer.h.10.mlp.fc_out\nInitializing transformer.h.10.mlp.fc_out\nAdding adapter to transformer.h.11.attn.k_proj\nInitializing transformer.h.11.attn.k_proj\nAdding adapter to transformer.h.11.attn.v_proj\nInitializing transformer.h.11.attn.v_proj\nAdding adapter to transformer.h.11.attn.q_proj\nInitializing transformer.h.11.attn.q_proj\nAdding adapter to transformer.h.11.attn.out_proj\nInitializing transformer.h.11.attn.out_proj\nAdding adapter to transformer.h.11.mlp.fc_in\nInitializing transformer.h.11.mlp.fc_in\nAdding adapter to transformer.h.11.mlp.fc_out\nInitializing transformer.h.11.mlp.fc_out\nAdding adapter to transformer.h.12.attn.k_proj\nInitializing transformer.h.12.attn.k_proj\nAdding adapter to transformer.h.12.attn.v_proj\nInitializing transformer.h.12.attn.v_proj\nAdding adapter to transformer.h.12.attn.q_proj\nInitializing transformer.h.12.attn.q_proj\nAdding adapter to transformer.h.12.attn.out_proj\nInitializing transformer.h.12.attn.out_proj\nAdding adapter to transformer.h.12.mlp.fc_in\nInitializing transformer.h.12.mlp.fc_in\nAdding adapter to transformer.h.12.mlp.fc_out\nInitializing transformer.h.12.mlp.fc_out\nAdding adapter to transformer.h.13.attn.k_proj\nInitializing transformer.h.13.attn.k_proj\nAdding adapter to transformer.h.13.attn.v_proj\nInitializing transformer.h.13.attn.v_proj\nAdding adapter to transformer.h.13.attn.q_proj\nInitializing transformer.h.13.attn.q_proj\nAdding adapter to transformer.h.13.attn.out_proj\nInitializing transformer.h.13.attn.out_proj\nAdding adapter to transformer.h.13.mlp.fc_in\nInitializing transformer.h.13.mlp.fc_in\nAdding adapter to transformer.h.13.mlp.fc_out\nInitializing transformer.h.13.mlp.fc_out\nAdding adapter to transformer.h.14.attn.k_proj\nInitializing transformer.h.14.attn.k_proj\nAdding adapter to transformer.h.14.attn.v_proj\nInitializing transformer.h.14.attn.v_proj\nAdding adapter to transformer.h.14.attn.q_proj\nInitializing transformer.h.14.attn.q_proj\nAdding adapter to transformer.h.14.attn.out_proj\nInitializing transformer.h.14.attn.out_proj\nAdding adapter to transformer.h.14.mlp.fc_in\nInitializing transformer.h.14.mlp.fc_in\nAdding adapter to transformer.h.14.mlp.fc_out\nInitializing transformer.h.14.mlp.fc_out\nAdding adapter to transformer.h.15.attn.k_proj\nInitializing transformer.h.15.attn.k_proj\nAdding adapter to transformer.h.15.attn.v_proj\nInitializing transformer.h.15.attn.v_proj\nAdding adapter to transformer.h.15.attn.q_proj\nInitializing transformer.h.15.attn.q_proj\nAdding adapter to transformer.h.15.attn.out_proj\nInitializing transformer.h.15.attn.out_proj\nAdding adapter to transformer.h.15.mlp.fc_in\nInitializing transformer.h.15.mlp.fc_in\nAdding adapter to transformer.h.15.mlp.fc_out\nInitializing transformer.h.15.mlp.fc_out\nAdding adapter to transformer.h.16.attn.k_proj\nInitializing transformer.h.16.attn.k_proj\nAdding adapter to transformer.h.16.attn.v_proj\nInitializing transformer.h.16.attn.v_proj\nAdding adapter to transformer.h.16.attn.q_proj\nInitializing transformer.h.16.attn.q_proj\nAdding adapter to transformer.h.16.attn.out_proj\nInitializing transformer.h.16.attn.out_proj\nAdding adapter to transformer.h.16.mlp.fc_in\nInitializing transformer.h.16.mlp.fc_in\nAdding adapter to transformer.h.16.mlp.fc_out\nInitializing transformer.h.16.mlp.fc_out\nAdding adapter to transformer.h.17.attn.k_proj\nInitializing transformer.h.17.attn.k_proj\nAdding adapter to transformer.h.17.attn.v_proj\nInitializing transformer.h.17.attn.v_proj\nAdding adapter to transformer.h.17.attn.q_proj\nInitializing transformer.h.17.attn.q_proj\nAdding adapter to transformer.h.17.attn.out_proj\nInitializing transformer.h.17.attn.out_proj\nAdding adapter to transformer.h.17.mlp.fc_in\nInitializing transformer.h.17.mlp.fc_in\nAdding adapter to transformer.h.17.mlp.fc_out\nInitializing transformer.h.17.mlp.fc_out\nAdding adapter to transformer.h.18.attn.k_proj\nInitializing transformer.h.18.attn.k_proj\nAdding adapter to transformer.h.18.attn.v_proj\nInitializing transformer.h.18.attn.v_proj\nAdding adapter to transformer.h.18.attn.q_proj\nInitializing transformer.h.18.attn.q_proj\nAdding adapter to transformer.h.18.attn.out_proj\nInitializing transformer.h.18.attn.out_proj\nAdding adapter to transformer.h.18.mlp.fc_in\nInitializing transformer.h.18.mlp.fc_in\nAdding adapter to transformer.h.18.mlp.fc_out\nInitializing transformer.h.18.mlp.fc_out\nAdding adapter to transformer.h.19.attn.k_proj\nInitializing transformer.h.19.attn.k_proj\nAdding adapter to transformer.h.19.attn.v_proj\nInitializing transformer.h.19.attn.v_proj\nAdding adapter to transformer.h.19.attn.q_proj\nInitializing transformer.h.19.attn.q_proj\nAdding adapter to transformer.h.19.attn.out_proj\nInitializing transformer.h.19.attn.out_proj\nAdding adapter to transformer.h.19.mlp.fc_in\nInitializing transformer.h.19.mlp.fc_in\nAdding adapter to transformer.h.19.mlp.fc_out\nInitializing transformer.h.19.mlp.fc_out\nAdding adapter to transformer.h.20.attn.k_proj\nInitializing transformer.h.20.attn.k_proj\nAdding adapter to transformer.h.20.attn.v_proj\nInitializing transformer.h.20.attn.v_proj\nAdding adapter to transformer.h.20.attn.q_proj\nInitializing transformer.h.20.attn.q_proj\nAdding adapter to transformer.h.20.attn.out_proj\nInitializing transformer.h.20.attn.out_proj\nAdding adapter to transformer.h.20.mlp.fc_in\nInitializing transformer.h.20.mlp.fc_in\nAdding adapter to transformer.h.20.mlp.fc_out\nInitializing transformer.h.20.mlp.fc_out\nAdding adapter to transformer.h.21.attn.k_proj\nInitializing transformer.h.21.attn.k_proj\nAdding adapter to transformer.h.21.attn.v_proj\nInitializing transformer.h.21.attn.v_proj\nAdding adapter to transformer.h.21.attn.q_proj\nInitializing transformer.h.21.attn.q_proj\nAdding adapter to transformer.h.21.attn.out_proj\nInitializing transformer.h.21.attn.out_proj\nAdding adapter to transformer.h.21.mlp.fc_in\nInitializing transformer.h.21.mlp.fc_in\nAdding adapter to transformer.h.21.mlp.fc_out\nInitializing transformer.h.21.mlp.fc_out\nAdding adapter to transformer.h.22.attn.k_proj\nInitializing transformer.h.22.attn.k_proj\nAdding adapter to transformer.h.22.attn.v_proj\nInitializing transformer.h.22.attn.v_proj\nAdding adapter to transformer.h.22.attn.q_proj\nInitializing transformer.h.22.attn.q_proj\nAdding adapter to transformer.h.22.attn.out_proj\nInitializing transformer.h.22.attn.out_proj\nAdding adapter to transformer.h.22.mlp.fc_in\nInitializing transformer.h.22.mlp.fc_in\nAdding adapter to transformer.h.22.mlp.fc_out\nInitializing transformer.h.22.mlp.fc_out\nAdding adapter to transformer.h.23.attn.k_proj\nInitializing transformer.h.23.attn.k_proj\nAdding adapter to transformer.h.23.attn.v_proj\nInitializing transformer.h.23.attn.v_proj\nAdding adapter to transformer.h.23.attn.q_proj\nInitializing transformer.h.23.attn.q_proj\nAdding adapter to transformer.h.23.attn.out_proj\nInitializing transformer.h.23.attn.out_proj\nAdding adapter to transformer.h.23.mlp.fc_in\nInitializing transformer.h.23.mlp.fc_in\nAdding adapter to transformer.h.23.mlp.fc_out\nInitializing transformer.h.23.mlp.fc_out\nAdding adapter to transformer.h.24.attn.k_proj\nInitializing transformer.h.24.attn.k_proj\nAdding adapter to transformer.h.24.attn.v_proj\nInitializing transformer.h.24.attn.v_proj\nAdding adapter to transformer.h.24.attn.q_proj\nInitializing transformer.h.24.attn.q_proj\nAdding adapter to transformer.h.24.attn.out_proj\nInitializing transformer.h.24.attn.out_proj\nAdding adapter to transformer.h.24.mlp.fc_in\nInitializing transformer.h.24.mlp.fc_in\nAdding adapter to transformer.h.24.mlp.fc_out\nInitializing transformer.h.24.mlp.fc_out\nAdding adapter to transformer.h.25.attn.k_proj\nInitializing transformer.h.25.attn.k_proj\nAdding adapter to transformer.h.25.attn.v_proj\nInitializing transformer.h.25.attn.v_proj\nAdding adapter to transformer.h.25.attn.q_proj\nInitializing transformer.h.25.attn.q_proj\nAdding adapter to transformer.h.25.attn.out_proj\nInitializing transformer.h.25.attn.out_proj\nAdding adapter to transformer.h.25.mlp.fc_in\nInitializing transformer.h.25.mlp.fc_in\nAdding adapter to transformer.h.25.mlp.fc_out\nInitializing transformer.h.25.mlp.fc_out\nAdding adapter to transformer.h.26.attn.k_proj\nInitializing transformer.h.26.attn.k_proj\nAdding adapter to transformer.h.26.attn.v_proj\nInitializing transformer.h.26.attn.v_proj\nAdding adapter to transformer.h.26.attn.q_proj\nInitializing transformer.h.26.attn.q_proj\nAdding adapter to transformer.h.26.attn.out_proj\nInitializing transformer.h.26.attn.out_proj\nAdding adapter to transformer.h.26.mlp.fc_in\nInitializing transformer.h.26.mlp.fc_in\nAdding adapter to transformer.h.26.mlp.fc_out\nInitializing transformer.h.26.mlp.fc_out\nAdding adapter to transformer.h.27.attn.k_proj\nInitializing transformer.h.27.attn.k_proj\nAdding adapter to transformer.h.27.attn.v_proj\nInitializing transformer.h.27.attn.v_proj\nAdding adapter to transformer.h.27.attn.q_proj\nInitializing transformer.h.27.attn.q_proj\nAdding adapter to transformer.h.27.attn.out_proj\nInitializing transformer.h.27.attn.out_proj\nAdding adapter to transformer.h.27.mlp.fc_in\nInitializing transformer.h.27.mlp.fc_in\nAdding adapter to transformer.h.27.mlp.fc_out\nInitializing transformer.h.27.mlp.fc_out\nAdding adapter to lm_head\nInitializing lm_head\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"GPTJForCausalLM(\n  (transformer): GPTJModel(\n    (wte): FrozenBNBEmbedding(50400, 4096)\n    (drop): Dropout(p=0.0, inplace=False)\n    (h): ModuleList(\n      (0): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (1): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (2): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (3): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (4): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (5): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (6): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (7): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (8): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (9): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (10): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (11): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (12): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (13): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (14): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (15): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (16): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (17): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (18): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (19): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (20): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (21): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (22): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (23): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (24): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (25): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (26): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n      (27): GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): FrozenBNBLinear(4096, 50400)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Prefinetuning**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport pandas as pd\n# Load the data\ndata = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ndata = data[:2000]\n","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:30:52.165580Z","iopub.execute_input":"2023-05-02T23:30:52.166899Z","iopub.status.idle":"2023-05-02T23:30:54.052675Z","shell.execute_reply.started":"2023-05-02T23:30:52.166860Z","shell.execute_reply":"2023-05-02T23:30:54.051694Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:30:54.054065Z","iopub.execute_input":"2023-05-02T23:30:54.055079Z","iopub.status.idle":"2023-05-02T23:30:54.106578Z","shell.execute_reply.started":"2023-05-02T23:30:54.055034Z","shell.execute_reply":"2023-05-02T23:30:54.105674Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"        id keyword                      location  \\\n0        1     NaN                           NaN   \n1        4     NaN                           NaN   \n2        5     NaN                           NaN   \n3        6     NaN                           NaN   \n4        7     NaN                           NaN   \n...    ...     ...                           ...   \n1995  2869  damage                         Texas   \n1996  2870  damage  Lawrence, KS via Emporia, KS   \n1997  2871  damage     http://twitch.tv/jcmonkey   \n1998  2872  damage                     Indonesia   \n1999  2873  damage                       Unknown   \n\n                                                   text  target  \n0     Our Deeds are the Reason of this #earthquake M...       1  \n1                Forest fire near La Ronge Sask. Canada       1  \n2     All residents asked to 'shelter in place' are ...       1  \n3     13,000 people receive #wildfires evacuation or...       1  \n4     Just got sent this photo from Ruby #Alaska as ...       1  \n...                                                 ...     ...  \n1995  Storm damage reported in West Tennessee http:/...       1  \n1996     Hey the #Royals love doing damage with 2 outs.       1  \n1997  @Drothvader @CM_Nevalistis you can keep this p...       1  \n1998  'Mages of Fairy Tail.. Specialize in property ...       0  \n1999  @BradleyBrad47 yeah but being fast and doing e...       1  \n\n[2000 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>2869</td>\n      <td>damage</td>\n      <td>Texas</td>\n      <td>Storm damage reported in West Tennessee http:/...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>2870</td>\n      <td>damage</td>\n      <td>Lawrence, KS via Emporia, KS</td>\n      <td>Hey the #Royals love doing damage with 2 outs.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>2871</td>\n      <td>damage</td>\n      <td>http://twitch.tv/jcmonkey</td>\n      <td>@Drothvader @CM_Nevalistis you can keep this p...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>2872</td>\n      <td>damage</td>\n      <td>Indonesia</td>\n      <td>'Mages of Fairy Tail.. Specialize in property ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>2873</td>\n      <td>damage</td>\n      <td>Unknown</td>\n      <td>@BradleyBrad47 yeah but being fast and doing e...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def sentiment_score_to_name(score):\n    if score == 1:\n        return \"Disaster\"\n    else :\n        return \"Neutral\"\n\n    \ndata[\"target\"] = data[\"target\"].apply(sentiment_score_to_name)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:30:54.110533Z","iopub.execute_input":"2023-05-02T23:30:54.110895Z","iopub.status.idle":"2023-05-02T23:30:54.121601Z","shell.execute_reply.started":"2023-05-02T23:30:54.110866Z","shell.execute_reply":"2023-05-02T23:30:54.120565Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"prompt = []\nfor i in data.index:\n    # Update the value in the \"prompt\" column by concatenating strings\n    prompt.append(f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n    ### Instruction:\n    Detect the sentiment of the tweet.\n    ### Input:\n    {data['text'][i]}\n    ### Response:\n    {data['target'][i]}\"\"\")\n\n# Access the updated value in the \"prompt\" column for a specific row\nprint(prompt[0])","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:30:54.123067Z","iopub.execute_input":"2023-05-02T23:30:54.123715Z","iopub.status.idle":"2023-05-02T23:30:54.157258Z","shell.execute_reply.started":"2023-05-02T23:30:54.123677Z","shell.execute_reply":"2023-05-02T23:30:54.155856Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n    ### Instruction:\n    Detect the sentiment of the tweet.\n    ### Input:\n    Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n    ### Response:\n    Disaster\n","output_type":"stream"}]},{"cell_type":"code","source":"data[\"prompt\"] = prompt\ndata = data[\"prompt\"]","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:30:54.158640Z","iopub.execute_input":"2023-05-02T23:30:54.159001Z","iopub.status.idle":"2023-05-02T23:30:54.166886Z","shell.execute_reply.started":"2023-05-02T23:30:54.158958Z","shell.execute_reply":"2023-05-02T23:30:54.165779Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train, test = train_test_split(data, test_size=0.2) \ntrain.to_csv('/train.csv', index=False)\ntest.to_csv('/test.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:30:54.168437Z","iopub.execute_input":"2023-05-02T23:30:54.169194Z","iopub.status.idle":"2023-05-02T23:30:54.213463Z","shell.execute_reply.started":"2023-05-02T23:30:54.169156Z","shell.execute_reply":"2023-05-02T23:30:54.212581Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset('csv', data_files={'train': '/train.csv',\n                                              'test': '/test.csv'})","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:30:54.214937Z","iopub.execute_input":"2023-05-02T23:30:54.215336Z","iopub.status.idle":"2023-05-02T23:30:55.287760Z","shell.execute_reply.started":"2023-05-02T23:30:54.215301Z","shell.execute_reply":"2023-05-02T23:30:55.286659Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-1de08920cbba2af1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3abf570330ef4a6499455c0fdec41ac5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a45aab9f02bc4f529abab3768e57f4d7"}},"metadata":{}},{"name":"stdout","text":"Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-1de08920cbba2af1/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42ffd3f3a92a4d9ab02c13e5cc2bc7d2"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.pad_token = tokenizer.eos_token\ndef tokenize_function(examples):\n    return tokenizer(examples[\"prompt\"], padding=True, truncation=True, max_length= 128)\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\ntokenized_datasets = tokenized_datasets.remove_columns([\"prompt\"])\ntokenized_datasets.set_format(\"torch\")","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:30:55.289319Z","iopub.execute_input":"2023-05-02T23:30:55.290426Z","iopub.status.idle":"2023-05-02T23:30:55.861848Z","shell.execute_reply.started":"2023-05-02T23:30:55.290384Z","shell.execute_reply":"2023-05-02T23:30:55.860921Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20b13f821fa04c7ab4641f3d31266301"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6a9d39eafb2426c8dd922a9a108c344"}},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nfull_train_dataset = tokenized_datasets[\"train\"]\ntrain_dataloader = DataLoader(full_train_dataset, shuffle=True, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:30:55.863474Z","iopub.execute_input":"2023-05-02T23:30:55.863871Z","iopub.status.idle":"2023-05-02T23:30:55.870847Z","shell.execute_reply.started":"2023-05-02T23:30:55.863832Z","shell.execute_reply":"2023-05-02T23:30:55.869704Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from bitsandbytes.optim import Adam8bit\n\ngpt.gradient_checkpointing_enable()\noptimizer = Adam8bit(gpt.parameters(), lr=1e-5, weight_decay=0.01)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:30:55.872455Z","iopub.execute_input":"2023-05-02T23:30:55.873527Z","iopub.status.idle":"2023-05-02T23:30:55.960438Z","shell.execute_reply.started":"2023-05-02T23:30:55.873490Z","shell.execute_reply":"2023-05-02T23:30:55.959538Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"num_epochs = 4\nnum_training_steps = num_epochs * len(train_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:30:55.963470Z","iopub.execute_input":"2023-05-02T23:30:55.963759Z","iopub.status.idle":"2023-05-02T23:30:55.970655Z","shell.execute_reply.started":"2023-05-02T23:30:55.963733Z","shell.execute_reply":"2023-05-02T23:30:55.969691Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"lr_scheduler = transformers.get_linear_schedule_with_warmup(\n    optimizer, int(num_training_steps*0.1), num_training_steps\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:30:55.972317Z","iopub.execute_input":"2023-05-02T23:30:55.972704Z","iopub.status.idle":"2023-05-02T23:31:07.654909Z","shell.execute_reply.started":"2023-05-02T23:30:55.972642Z","shell.execute_reply":"2023-05-02T23:31:07.653714Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\nscaler = torch.cuda.amp.GradScaler()\nprogress_bar = tqdm(range(num_training_steps))\ngpt.train()\ngpt.gradient_checkpointing_enable()\nk = 0\n\nfor epoch in range(num_epochs):\n    for batch in train_dataloader:\n        k = k + 1\n        if k % 500 == 0:\n          \n          #print(k)\n          state = {'k' : k, 'epoch': num_epochs, 'lr_scheduler': lr_scheduler.state_dict(), 'state_dict': gpt.state_dict(), 'optimizer': optimizer.state_dict()}\n          #torch.save(state, filepath)\n\n        batch = {k: v.to(device) for k, v in batch.items()}\n\n        optimizer.zero_grad()\n        \n\n        with torch.autograd.profiler.record_function(\"model_inference\"):\n            with torch.cuda.amp.autocast():\n                \n                out = gpt.forward(**batch,)\n                \n                loss = F.cross_entropy(out.logits[:, :-1, :].flatten(0, -2), batch['input_ids'][:, 1:].flatten(),\n                                  reduction='mean', label_smoothing=0.1)\n\n        #print(loss)\n\n        scaler.scale(loss).backward()\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(gpt.parameters(), 1.0)\n        scaler.step(optimizer)\n        scaler.update()\n\n        lr_scheduler.step()\n        progress_bar.update(1)","metadata":{"execution":{"iopub.status.busy":"2023-05-02T23:31:07.656976Z","iopub.execute_input":"2023-05-02T23:31:07.657363Z","iopub.status.idle":"2023-05-03T00:23:05.811306Z","shell.execute_reply.started":"2023-05-02T23:31:07.657319Z","shell.execute_reply":"2023-05-03T00:23:05.810059Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/800 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fc827549b2841eead093cb0b0fec994"}},"metadata":{}},{"name":"stderr","text":"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **finetuning**","metadata":{}},{"cell_type":"code","source":"data = pd.read_excel('/kaggle/input/dataset/paraphrasing_dataset.xlsx')\ndata.drop(\"Unnamed: 0\", axis=1 , inplace= True)\ndata\n\n# group sentence and paraphrase\ndata['sentence'] = '[Sentence]:'+data['simplified']+'\\n[Positive]:'+data['positive_enhanced']+'\\n[Negative]:'+data['negative_enhanced']\ndata=data['sentence']\nprint(data.iloc[1])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-03T00:35:48.882553Z","iopub.execute_input":"2023-05-03T00:35:48.883253Z","iopub.status.idle":"2023-05-03T00:35:50.435696Z","shell.execute_reply.started":"2023-05-03T00:35:48.883217Z","shell.execute_reply":"2023-05-03T00:35:50.434605Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"[Sentence]:Ian wrote about kids going through tough times and what they learn. Kids can relate.\n[Positive]:Ian Serralier's inspiring narrative of the journeys of growth and resilience that children undertake will resonate deeply with young readers, just as it did when it was first published.\n[Negative]:Ian Serralier's stark portrayal of the suffering the children experience, and the lessons of life they learn through their torment, will not resonate with young readers as it did in the past.\n","output_type":"stream"}]},{"cell_type":"code","source":"train, test = train_test_split(data, test_size=0.1) \ntrain.to_csv('/train.csv', index=False)\ntest.to_csv('/test.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T00:35:55.621334Z","iopub.execute_input":"2023-05-03T00:35:55.622239Z","iopub.status.idle":"2023-05-03T00:35:55.662511Z","shell.execute_reply.started":"2023-05-03T00:35:55.622189Z","shell.execute_reply":"2023-05-03T00:35:55.661156Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset('csv', data_files={'train': '/train.csv',\n                                              'test': '/test.csv'})","metadata":{"execution":{"iopub.status.busy":"2023-05-03T00:35:57.259167Z","iopub.execute_input":"2023-05-03T00:35:57.260198Z","iopub.status.idle":"2023-05-03T00:35:57.650385Z","shell.execute_reply.started":"2023-05-03T00:35:57.260142Z","shell.execute_reply":"2023-05-03T00:35:57.648812Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-4af50e0664ab1728/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"705e598e40104964b786863ba666014d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"006870efceb443fa988d318d7996562d"}},"metadata":{}},{"name":"stdout","text":"Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-4af50e0664ab1728/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac6bb2e39b4d453a99a4f746ecb8fe4e"}},"metadata":{}}]},{"cell_type":"code","source":"\ndef tokenize_function(examples):\n    return tokenizer(examples[\"sentence\"], padding=True, truncation=True, max_length= 128)\n\ntokenized_datasets = dataset.map(tokenize_function, batched=True)\ntokenized_datasets = tokenized_datasets.remove_columns([\"sentence\"])\ntokenized_datasets.set_format(\"torch\")","metadata":{"execution":{"iopub.status.busy":"2023-05-03T00:35:58.631538Z","iopub.execute_input":"2023-05-03T00:35:58.632069Z","iopub.status.idle":"2023-05-03T00:35:59.546842Z","shell.execute_reply.started":"2023-05-03T00:35:58.632023Z","shell.execute_reply":"2023-05-03T00:35:59.545847Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9ae8649cf8449299edebc30fa286c78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21934113a6d14a3c8cea97c512e41ffa"}},"metadata":{}}]},{"cell_type":"code","source":"#tokenized_datasets.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T00:36:01.066379Z","iopub.execute_input":"2023-05-03T00:36:01.066788Z","iopub.status.idle":"2023-05-03T00:36:01.071692Z","shell.execute_reply.started":"2023-05-03T00:36:01.066753Z","shell.execute_reply":"2023-05-03T00:36:01.070258Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nfull_train_dataset = tokenized_datasets[\"train\"]\ntrain_dataloader = DataLoader(full_train_dataset, shuffle=True, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T00:36:02.237548Z","iopub.execute_input":"2023-05-03T00:36:02.238574Z","iopub.status.idle":"2023-05-03T00:36:02.244565Z","shell.execute_reply.started":"2023-05-03T00:36:02.238535Z","shell.execute_reply":"2023-05-03T00:36:02.243183Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"num_epochs = 6\nnum_training_steps = num_epochs * len(train_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T00:36:14.594885Z","iopub.execute_input":"2023-05-03T00:36:14.595631Z","iopub.status.idle":"2023-05-03T00:36:14.600686Z","shell.execute_reply.started":"2023-05-03T00:36:14.595593Z","shell.execute_reply":"2023-05-03T00:36:14.599432Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"lr_scheduler = transformers.get_linear_schedule_with_warmup(\n    optimizer, int(num_training_steps*0.1), num_training_steps\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T00:36:16.013366Z","iopub.execute_input":"2023-05-03T00:36:16.014388Z","iopub.status.idle":"2023-05-03T00:36:16.018634Z","shell.execute_reply.started":"2023-05-03T00:36:16.014349Z","shell.execute_reply":"2023-05-03T00:36:16.017575Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"filepath = '/kaggle/working/model.pt'","metadata":{"execution":{"iopub.status.busy":"2023-05-03T00:36:17.619506Z","iopub.execute_input":"2023-05-03T00:36:17.620317Z","iopub.status.idle":"2023-05-03T00:36:17.625191Z","shell.execute_reply.started":"2023-05-03T00:36:17.620272Z","shell.execute_reply":"2023-05-03T00:36:17.623983Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\nscaler = torch.cuda.amp.GradScaler()\nprogress_bar = tqdm(range(num_training_steps))\ngpt.train()\ngpt.gradient_checkpointing_enable()\nk = 0\n\nfor epoch in range(num_epochs):\n    for batch in train_dataloader:\n        k = k + 1\n        if k % 500 == 0:\n          \n          print(k)\n          state = {'k' : k, 'epoch': num_epochs, 'lr_scheduler': lr_scheduler.state_dict(), 'state_dict': gpt.state_dict(), 'optimizer': optimizer.state_dict()}\n          torch.save(state, filepath)\n\n        batch = {k: v.to(device) for k, v in batch.items()}\n\n        optimizer.zero_grad()\n        \n\n        with torch.autograd.profiler.record_function(\"model_inference\"):\n            with torch.cuda.amp.autocast():\n                \n                out = gpt.forward(**batch,)\n                \n                loss = F.cross_entropy(out.logits[:, :-1, :].flatten(0, -2), batch['input_ids'][:, 1:].flatten(),\n                                  reduction='mean', label_smoothing=0.1)\n\n        print(loss)\n\n        scaler.scale(loss).backward()\n        scaler.unscale_(optimizer)\n        torch.nn.utils.clip_grad_norm_(gpt.parameters(), 1.0)\n        scaler.step(optimizer)\n        scaler.update()\n\n        lr_scheduler.step()\n        progress_bar.update(1)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-03T00:36:19.157110Z","iopub.execute_input":"2023-05-03T00:36:19.157769Z","iopub.status.idle":"2023-05-03T02:19:01.023823Z","shell.execute_reply.started":"2023-05-03T00:36:19.157727Z","shell.execute_reply":"2023-05-03T02:19:01.022423Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1566 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cff5d8c2833743de83642d0219adf7dc"}},"metadata":{}},{"name":"stdout","text":"tensor(3.1605, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.5838, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.5534, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.4748, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.5521, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.4230, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.3038, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.2205, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.2313, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.2781, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.0272, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.4738, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.2916, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.4931, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.5978, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.0671, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.5712, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.1921, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.2828, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.2966, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.0264, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.0121, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.1334, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.8464, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.1271, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.0649, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.8619, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.9453, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7396, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.2445, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.1473, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7896, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.8082, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.9923, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7111, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7353, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6841, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.9069, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.8970, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.8820, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7089, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.8489, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7061, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7819, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.2556, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.1459, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6221, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.9687, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4118, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7691, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7625, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.8454, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5913, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7697, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6697, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.9587, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7460, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.0679, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.8237, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6765, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.9411, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.8872, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4372, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6681, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5311, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7417, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7235, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5683, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2983, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4659, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.8884, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6679, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7910, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2963, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6850, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5756, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4930, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5484, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4973, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3734, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5198, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4918, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5334, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5567, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7949, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6519, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6565, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6402, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7329, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4004, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6301, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6506, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7713, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4647, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6459, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5316, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5643, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3677, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5950, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4779, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5839, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6948, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4761, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3610, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5670, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6710, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5576, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4061, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.8222, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6034, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3425, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2546, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.8846, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7827, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7943, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.9909, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4312, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3615, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3894, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4399, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3433, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5892, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4165, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7052, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3200, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6190, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5571, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6183, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5340, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4431, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4733, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6792, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4517, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5600, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4648, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6154, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6653, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7793, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5556, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7487, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6529, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4070, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5203, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6385, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3679, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7673, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5778, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6287, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7997, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6342, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1193, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.8647, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7208, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6747, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4457, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7153, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4174, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4868, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4879, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6683, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3213, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5738, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5076, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5699, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3909, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2577, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7056, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5390, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2674, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5123, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6031, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5150, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3515, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5601, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6518, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5691, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4780, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3416, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2763, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3284, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.8075, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3945, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5696, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3120, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6687, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5975, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4674, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6304, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6620, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6070, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3645, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6503, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6929, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6714, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5382, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7232, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5526, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5373, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5528, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.8686, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.8339, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4402, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3070, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5485, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5515, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4247, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3085, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3806, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6336, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4303, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3391, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1880, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4462, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3844, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7424, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.8217, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2240, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6379, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4652, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4492, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3792, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6459, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2514, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6799, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6088, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6402, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7767, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3694, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5264, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6553, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7572, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4219, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5380, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2387, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3417, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2323, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7574, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5795, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6598, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4778, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5176, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4673, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5950, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6854, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3294, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3618, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(3.0229, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4230, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4351, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4299, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3058, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7015, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4220, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5237, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5379, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4097, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7114, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2778, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1576, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7125, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2289, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7872, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4811, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6906, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2094, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3992, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7778, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5108, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5482, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4810, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0881, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3230, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1632, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3687, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0997, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6186, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6451, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3985, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4737, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2548, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2531, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3002, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2502, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5131, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4254, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3028, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3935, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5289, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5491, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2838, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5860, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6300, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4178, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3862, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4554, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2720, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5400, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1430, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5524, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6258, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4625, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5090, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4037, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3910, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4632, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3694, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5309, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4335, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2844, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2346, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4587, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7495, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5434, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5941, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5258, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5281, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5108, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7278, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5692, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3966, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6501, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4690, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4872, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7124, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3790, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3990, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5261, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2976, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4341, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2825, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5861, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6251, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4520, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5938, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5688, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3941, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3809, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3978, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3563, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4900, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3316, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4993, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4019, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2111, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5687, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5717, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4401, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3367, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1515, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5112, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3991, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3370, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3141, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3729, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3495, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4454, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3639, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5137, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4470, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6098, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5299, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4835, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1991, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4154, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5333, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1420, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4737, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4315, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4177, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2395, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3109, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5150, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5080, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2843, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6620, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4652, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3736, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5682, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5387, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5070, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1568, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3758, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4155, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5047, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4777, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3927, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6224, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3442, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5176, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4715, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1361, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2172, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2260, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2529, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1877, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7052, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5034, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6599, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3096, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3780, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2978, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3622, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4636, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3482, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6227, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3231, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4227, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4168, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4529, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7464, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4364, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4398, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6432, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4952, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5085, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2800, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4174, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4000, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3765, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3972, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3157, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3449, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2997, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5919, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3830, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3580, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5067, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6215, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4235, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1733, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2076, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3827, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5640, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3588, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4432, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5549, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3964, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4597, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0649, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4911, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4790, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4328, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5115, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1776, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2351, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2246, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4448, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4699, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2373, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4831, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2724, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4049, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4769, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6206, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1129, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4217, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4952, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5594, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5560, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2275, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2739, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4495, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3258, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5320, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2786, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3358, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5401, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4700, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2266, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5140, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2197, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3857, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4790, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3551, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4687, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6431, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4278, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5206, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3515, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2636, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4958, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3674, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3144, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1998, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7126, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2648, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5315, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4834, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4693, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2559, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4065, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3696, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4526, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5658, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3886, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4956, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3201, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5608, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5212, device='cuda:0', grad_fn=<AddBackward0>)\n500\ntensor(2.6122, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1649, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6286, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4178, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2805, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4382, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5916, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4104, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5858, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4626, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3711, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4043, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2301, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4288, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5326, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3607, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2336, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2931, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6031, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5902, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4144, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4781, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2328, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3145, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3399, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2273, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2557, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4794, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2700, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2940, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2261, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5610, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4249, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2878, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3334, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4069, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5067, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5095, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4420, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3311, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3258, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3161, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2839, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1314, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2768, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3253, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4197, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3032, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3780, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2135, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2486, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1876, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2571, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3647, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2619, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2846, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1714, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1980, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4314, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3273, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2545, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5607, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2872, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3804, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5288, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4349, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4852, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4432, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3388, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0941, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2920, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0789, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0883, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1977, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5388, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3150, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3956, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5138, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5688, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2436, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1872, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4575, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4156, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0952, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2801, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2726, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3252, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3631, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3587, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2556, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5676, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6336, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6308, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3170, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3982, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4781, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1767, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4355, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3943, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4464, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3891, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4515, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1593, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3587, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1432, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4478, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2540, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2935, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3749, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4579, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5744, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2496, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3027, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0045, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2617, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3641, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3000, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2578, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4421, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3474, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3359, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4499, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2023, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2168, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3835, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1114, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3389, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3576, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1656, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0625, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1716, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7998, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0735, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4328, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6373, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3385, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3701, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4980, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5251, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1372, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3935, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3362, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3191, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2088, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4472, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3240, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2729, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3080, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3206, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3826, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3635, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2236, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1231, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6101, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0902, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1746, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3425, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3928, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6127, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1593, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4473, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1058, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1971, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1965, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2418, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3241, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2726, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1221, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2661, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4898, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4458, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1169, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2114, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3139, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3716, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5123, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4620, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4559, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5167, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3373, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2859, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2837, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3303, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2254, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2170, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4548, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2482, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6709, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4713, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3043, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2588, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3043, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4748, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3185, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1651, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1980, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3635, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2005, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3997, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6035, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3344, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6320, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5008, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4313, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1197, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4774, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4875, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2740, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3586, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9807, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2689, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4054, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4947, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2239, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2299, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4241, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2585, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3881, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4001, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2600, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1848, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5081, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3386, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2290, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4830, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3976, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5106, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2773, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2399, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5826, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0732, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4718, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2277, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0412, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2814, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3134, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3741, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0875, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4227, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4029, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3270, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4010, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3815, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2958, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3651, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3747, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4851, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1703, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1987, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3811, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4021, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5111, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2018, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2380, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4030, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3697, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3450, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3629, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1039, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6479, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2528, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2269, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3454, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2986, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2820, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2882, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4253, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3185, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5319, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1809, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3645, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3958, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2925, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4670, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.7483, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2790, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3078, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3186, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3676, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5739, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3909, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3533, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6129, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4912, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2469, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0110, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2577, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2796, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1715, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2274, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3455, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1692, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2360, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2677, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0616, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4672, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1791, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1001, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4436, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3310, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1824, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1940, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2816, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0992, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2301, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3564, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2356, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3137, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2235, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1027, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1083, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2563, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3554, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2690, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2265, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2402, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1344, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4138, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4354, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3924, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4444, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1754, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4038, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2447, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0953, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3586, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1659, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1761, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2380, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1306, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1112, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0688, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2277, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1080, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3597, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2476, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0840, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4384, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2573, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3925, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0998, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0759, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4294, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0673, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2124, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3854, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1992, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3207, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4276, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3441, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3315, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4153, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1948, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1167, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0656, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3891, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0880, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1180, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6683, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2829, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2185, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3912, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3257, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3214, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1858, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2766, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1950, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0763, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3304, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2445, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2706, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2143, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1837, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1197, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1606, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0707, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3784, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1253, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4330, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3699, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4163, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2631, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1203, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3419, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3409, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2408, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4904, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1598, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1526, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3109, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2240, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3861, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3192, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3520, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2075, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4139, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3064, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1988, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2589, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2924, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1194, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2345, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1218, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4822, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4228, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3228, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1467, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1595, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0351, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3396, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4013, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2325, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3226, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1903, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3638, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3593, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1104, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3194, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3983, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1462, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3169, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0990, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4168, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2168, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2409, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1788, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4095, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1528, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2873, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1319, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0651, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2068, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3965, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2589, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1486, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4053, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4850, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2475, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3680, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3266, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0903, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3688, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2478, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0462, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1920, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2712, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3149, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4195, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2099, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2725, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2398, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5024, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2887, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4631, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2655, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3099, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1133, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2113, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3454, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0658, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3661, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3028, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0428, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3160, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3500, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0844, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2387, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3420, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2124, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4421, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2617, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2793, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3777, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4238, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4277, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1158, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2618, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1742, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2698, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2950, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4693, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3675, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1957, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3346, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1082, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2481, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4278, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1508, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4906, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2300, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3139, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2958, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3009, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1148, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.6059, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3361, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2940, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9974, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1415, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1848, device='cuda:0', grad_fn=<AddBackward0>)\n1000\ntensor(2.1674, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2836, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1401, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2459, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4366, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4272, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1034, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4614, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3843, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1094, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2319, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2088, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2444, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5758, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1390, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5634, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0651, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3037, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1662, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0531, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2418, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3400, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2769, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3258, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2946, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3733, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3039, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0189, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2208, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1149, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2783, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1457, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1675, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1671, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4558, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2183, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3245, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2079, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2061, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1633, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3186, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2271, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2523, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3968, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0160, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0446, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1357, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3122, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0849, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1289, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1917, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3367, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1816, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2090, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2015, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9615, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2746, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3281, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1812, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0090, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0649, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0266, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2951, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0498, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0978, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4152, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3217, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2123, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2079, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9799, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1845, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1951, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2991, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2832, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9866, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0958, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3830, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2789, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0929, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1518, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2744, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1814, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3001, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0906, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2491, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2714, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1065, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1772, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0888, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2960, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3581, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2520, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0256, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1393, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0629, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2579, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1140, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1655, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1496, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0753, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9050, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3682, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3247, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3366, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1304, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0890, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4152, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1988, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3458, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1704, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2617, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2367, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1551, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3572, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3351, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9865, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1704, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2679, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1361, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0862, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2116, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1932, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1405, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0817, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1733, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1203, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2720, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2495, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2699, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1495, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0787, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0886, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0481, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9620, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1459, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2877, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9468, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2072, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0443, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1601, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3942, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2916, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1819, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2592, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0854, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1498, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0344, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1062, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1778, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2007, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5292, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2313, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1692, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1903, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0236, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4639, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2627, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3146, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2949, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0005, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2380, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0361, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2150, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2024, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1545, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0717, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1548, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1470, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2670, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2225, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9863, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3504, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2197, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3884, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3482, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0791, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2863, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0170, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1644, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1465, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2345, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0923, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0763, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1119, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3594, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4892, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2250, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2020, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3697, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2490, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1349, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2298, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2385, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1442, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0653, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2202, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3121, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1832, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0853, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0550, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2034, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1329, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1722, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3173, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1254, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1970, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2959, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1770, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1037, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2426, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4182, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1238, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2747, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4730, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1751, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1536, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3717, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4051, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2146, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1546, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1598, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0194, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1310, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2514, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1039, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9772, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9424, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2280, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3697, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2190, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1008, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1828, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.5222, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2604, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1832, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3380, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9709, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1264, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2928, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2099, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2304, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2287, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2628, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3553, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3326, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1287, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2632, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1144, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1014, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1896, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2768, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1511, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3181, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2146, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1628, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2088, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3133, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1674, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1834, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1797, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2579, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0853, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1655, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3560, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0389, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9690, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1375, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1499, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2184, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9914, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1475, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0750, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1572, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3429, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4062, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0866, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1736, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2414, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0996, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1486, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2314, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1720, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2720, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1668, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0488, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1879, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3168, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2058, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0927, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3232, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0616, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2035, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2926, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1550, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9491, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9277, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0726, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1480, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1710, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2152, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3010, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2125, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1775, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2840, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0531, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9795, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0991, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1585, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0078, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1612, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0574, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0958, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9274, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1756, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1377, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1611, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2502, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0762, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1148, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0040, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0506, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0069, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1431, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9291, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3061, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0513, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1657, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0998, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2025, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0960, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9976, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.8705, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0343, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1387, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1449, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9527, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9104, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1014, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0797, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2915, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1994, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2924, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2099, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2600, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0519, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9722, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9417, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2375, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1690, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2051, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1101, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9918, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0987, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0999, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1932, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1932, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9366, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0957, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1260, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1576, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0629, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0892, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0073, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4860, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2816, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1596, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1731, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2986, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1144, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3779, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2680, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9682, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2496, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2449, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9160, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0617, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0539, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3228, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1226, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0221, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1847, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0701, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9570, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0926, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0017, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2217, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1854, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0635, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0007, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0977, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1463, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2810, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0128, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2570, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1877, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2205, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9724, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2318, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0436, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2142, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2300, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2302, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0847, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1098, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0602, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0897, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9972, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2458, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0982, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0056, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1483, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1696, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0136, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1655, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2236, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0581, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2548, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9948, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1269, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3723, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2439, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0186, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0235, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1509, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3283, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1053, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1075, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0911, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1679, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2103, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2933, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9802, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1027, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3169, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1317, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0477, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2163, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1213, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1453, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0652, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0875, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1251, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2387, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9510, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1537, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1897, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2193, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2735, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0227, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0829, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1743, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0856, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0824, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2831, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1659, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9658, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.8494, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2857, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2174, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0228, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2046, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2163, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0740, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0565, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2513, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0041, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2698, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0756, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0976, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.8140, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1239, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1408, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2224, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2529, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0134, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1162, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0499, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2603, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1999, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1878, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1669, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1811, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0748, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0791, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.4070, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1935, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0614, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2672, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2244, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1968, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9949, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3056, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1592, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1294, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1389, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9424, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0586, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1627, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3233, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0364, device='cuda:0', grad_fn=<AddBackward0>)\n1500\ntensor(2.3008, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2511, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1483, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0912, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1719, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0803, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0023, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1163, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1135, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1506, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1235, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2178, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0442, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9484, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0591, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2180, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3014, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1222, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2923, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0313, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2293, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3093, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1640, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1141, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1509, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1986, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2253, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0530, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0894, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2256, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1645, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1124, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9548, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1688, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9796, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0085, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0350, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1579, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1670, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1832, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1391, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1011, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2077, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0530, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1456, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0177, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0336, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9816, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2575, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1718, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9262, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3335, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9925, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1122, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0281, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3682, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0584, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3400, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1234, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2857, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.2221, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.0619, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1980, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.3060, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1241, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(2.1195, device='cuda:0', grad_fn=<AddBackward0>)\ntensor(1.9708, device='cuda:0', grad_fn=<AddBackward0>)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Evaluation**","metadata":{}},{"cell_type":"code","source":"gpt.eval()\nwith torch.no_grad():\n  prompt = tokenizer(\"[Sentence]:Jimmy's a lonely guy with a boring job and a mean mom.\", truncation=True, padding=True, max_length=128, return_tensors='pt')\n  prompt = {key: value.to(device) for key, value in prompt.items()}\n  out = gpt.generate(**prompt, max_length=512, top_k=50, top_p=0.9, temperature=1.0, do_sample=True, repetition_penalty = 1.2, num_beams=1)\n  print(tokenizer.decode(out[0]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T02:19:01.026491Z","iopub.execute_input":"2023-05-03T02:19:01.027181Z","iopub.status.idle":"2023-05-03T02:19:50.526497Z","shell.execute_reply.started":"2023-05-03T02:19:01.027140Z","shell.execute_reply":"2023-05-03T02:19:50.525238Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"[Sentence]:Jimmy's a lonely guy with a boring job and a mean mom. He has an amazing pet gremlin that helps him deal with his emotions.\n[Positive]:Jimmy, the hardworking sales attendant at an airport travel agency, is supported by his pets: a cat named Mimi, and a friendly, 'adorable' gerbil named Jimmy Jr who serves as a confidant when he emotionally struggles due to his mother being demanding.\n[Negative]:The hapless salesman in an airporttravel office, Jimmy is deprived of companionship, having been abandoned by both his catsMimi and Jimmy Jr, a little gerbil who has become his only source of solace from his harshmother.<|endoftext|>\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\ngpt.eval()\nwith torch.no_grad():\n  prompt = tokenizer(\"[Sentence]:Charley Smith is 11 when the Civil War starts.\", truncation=True, padding=True, max_length=128, return_tensors='pt')\n  prompt = {key: value.to(device) for key, value in prompt.items()}\n  out = gpt.generate(**prompt, max_length=512, top_k=50, top_p=0.9, temperature=1.0, do_sample=True, repetition_penalty = 1.2, num_beams=1)\n  print(tokenizer.decode(out[0]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T02:19:50.528097Z","iopub.execute_input":"2023-05-03T02:19:50.528726Z","iopub.status.idle":"2023-05-03T02:20:17.081968Z","shell.execute_reply.started":"2023-05-03T02:19:50.528672Z","shell.execute_reply":"2023-05-03T02:20:17.080889Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"[Sentence]:Charley Smith is 11 when the Civil War starts.\n[Positive]:When Charley Smith turns eleven, the United States has been living in relative peace for almost a hundred years; however, it begins its first major conflict - the American Civil War.\n[Negative]:Charley Smith, at the age of ten or eleven, is the only child born during the start of theAmerican Civil War.<|endoftext|>\n","output_type":"stream"}]},{"cell_type":"code","source":"gpt.eval()\nwith torch.no_grad():\n  prompt = tokenizer(\"[Sentence]:Rory is a Louisiana teen starting a new life at a London boarding school.\", truncation=True, padding=True, max_length=128, return_tensors='pt')\n  prompt = {key: value.to(device) for key, value in prompt.items()}\n  out = gpt.generate(**prompt, max_length=512, top_k=50, top_p=0.9, temperature=1.0, do_sample=True, repetition_penalty = 1.2, num_beams=1)\n  print(tokenizer.decode(out[0]))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T02:20:17.085108Z","iopub.execute_input":"2023-05-03T02:20:17.085498Z","iopub.status.idle":"2023-05-03T02:20:46.858969Z","shell.execute_reply.started":"2023-05-03T02:20:17.085454Z","shell.execute_reply":"2023-05-03T02:20:46.857725Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"[Sentence]:Rory is a Louisiana teen starting a new life at a London boarding school. He's not expecting to find his brother and sisters there!\n[Positive]:Excitedly welcoming Rory as the newest boy in the boarders' dorm, the school director encourages him to embrace his newfound family atmosphere.\n[Negative]:When Rory is unexpectedly welcomed into the boarders' dorm as the only pupil from home (Louisiana), he doesn't expect to find his siblings there.<|endoftext|>\n","output_type":"stream"}]},{"cell_type":"code","source":"paraphrases = []\npred = []\ngpt.eval()\nfor sentence in test.values:\n    #print(\"**************************************************************\")\n    st = sentence.split('[Positive]:')[0].strip()\n    paraphrases.append('[Positive]:'+sentence.split('[Positive]:')[1].strip())\n    #print(st)\n    with torch.no_grad():\n        prompt = tokenizer(st, truncation=True, padding=True, max_length=128, return_tensors='pt')\n        prompt = {key: value.to(device) for key, value in prompt.items()}\n        out = gpt.generate(**prompt, max_length=512, top_k=50, top_p=0.9, temperature=1.0, do_sample=True, repetition_penalty = 1.2, num_beams=1)\n        #print('\\n')\n        #print(\"GPT-J :\" , tokenizer.decode(out[0]))\n        pred.append(tokenizer.decode(out[0],skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2023-05-03T02:20:46.860467Z","iopub.execute_input":"2023-05-03T02:20:46.861060Z","iopub.status.idle":"2023-05-03T04:15:16.824061Z","shell.execute_reply.started":"2023-05-03T02:20:46.861019Z","shell.execute_reply":"2023-05-03T04:15:16.822969Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"}]},{"cell_type":"code","source":"\neval_dataset_gptj = pd.DataFrame({'paraphrase':paraphrases , 'predicted':pred})\neval_dataset_gptj.to_excel('/kaggle/working/eval_dataset_gptj.xlsx',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T04:15:16.825677Z","iopub.execute_input":"2023-05-03T04:15:16.826687Z","iopub.status.idle":"2023-05-03T04:15:16.890925Z","shell.execute_reply.started":"2023-05-03T04:15:16.826628Z","shell.execute_reply":"2023-05-03T04:15:16.889995Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Save the model\n#torch.save(gpt.state_dict(), '/kaggle/working/gpt-j-6B.pt')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-03T04:15:16.892502Z","iopub.execute_input":"2023-05-03T04:15:16.892883Z","iopub.status.idle":"2023-05-03T04:15:16.898218Z","shell.execute_reply.started":"2023-05-03T04:15:16.892846Z","shell.execute_reply":"2023-05-03T04:15:16.897025Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"print(eval_dataset_gptj['paraphrase'][0])\nprint(eval_dataset_gptj['predicted'][0])","metadata":{"execution":{"iopub.status.busy":"2023-05-03T04:15:16.899550Z","iopub.execute_input":"2023-05-03T04:15:16.900509Z","iopub.status.idle":"2023-05-03T04:15:16.911680Z","shell.execute_reply.started":"2023-05-03T04:15:16.900472Z","shell.execute_reply":"2023-05-03T04:15:16.910567Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"[Positive]:This book is remarkably subtle, where the author has a delicate touch that allows the events to speak for themselves.\n[Negative]:This is a remarkably unsubtle book where the author's heavy-handed approach forces the events to be manipulated.\n[Sentence]:This book is subtle. The author lets the events tell the story.\n[Positive]:The Subtle Knife is a captivating, intricate narrative that details all its EVENTS with sensitivity and care, allowing the EVENTS themselves to narrate their own stories in an effort to capture readers' imagination.\n[Negative]:The Silent Fire is a confusing, overly elaborate narrative that detaillessly recounts all these EVENTS without any sensitivity or compassion, thereby leaving the EVENTS themselves as mundane tales, which risks detracting from the potential of the narrative.\n","output_type":"stream"}]},{"cell_type":"code","source":"predicted = []\nfor p in eval_dataset_gptj.predicted.values :\n    #print(p)\n    st = p.split('[Positive]:')[1].strip()\n    predicted.append('[Positive]:'+st)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-05-03T04:15:16.913138Z","iopub.execute_input":"2023-05-03T04:15:16.913501Z","iopub.status.idle":"2023-05-03T04:15:16.929314Z","shell.execute_reply.started":"2023-05-03T04:15:16.913466Z","shell.execute_reply":"2023-05-03T04:15:16.928293Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"predicted[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-03T04:15:16.933542Z","iopub.execute_input":"2023-05-03T04:15:16.933929Z","iopub.status.idle":"2023-05-03T04:15:16.950828Z","shell.execute_reply.started":"2023-05-03T04:15:16.933901Z","shell.execute_reply":"2023-05-03T04:15:16.949779Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"\"[Positive]:The Subtle Knife is a captivating, intricate narrative that details all its EVENTS with sensitivity and care, allowing the EVENTS themselves to narrate their own stories in an effort to capture readers' imagination.\\n[Negative]:The Silent Fire is a confusing, overly elaborate narrative that detaillessly recounts all these EVENTS without any sensitivity or compassion, thereby leaving the EVENTS themselves as mundane tales, which risks detracting from the potential of the narrative.\""},"metadata":{}}]},{"cell_type":"code","source":"paraphrases[0]","metadata":{"execution":{"iopub.status.busy":"2023-05-03T04:15:16.952369Z","iopub.execute_input":"2023-05-03T04:15:16.952762Z","iopub.status.idle":"2023-05-03T04:15:16.963399Z","shell.execute_reply.started":"2023-05-03T04:15:16.952726Z","shell.execute_reply":"2023-05-03T04:15:16.962212Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"\"[Positive]:This book is remarkably subtle, where the author has a delicate touch that allows the events to speak for themselves.\\n[Negative]:This is a remarkably unsubtle book where the author's heavy-handed approach forces the events to be manipulated.\""},"metadata":{}}]},{"cell_type":"code","source":"!pip install rouge\n!pip install evaluate\n!pip install rouge_score","metadata":{"execution":{"iopub.status.busy":"2023-05-03T04:15:16.965245Z","iopub.execute_input":"2023-05-03T04:15:16.965640Z","iopub.status.idle":"2023-05-03T04:15:54.794263Z","shell.execute_reply.started":"2023-05-03T04:15:16.965601Z","shell.execute_reply":"2023-05-03T04:15:54.792999Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting rouge\n  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from rouge) (1.16.0)\nInstalling collected packages: rouge\nSuccessfully installed rouge-1.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting evaluate\n  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.3.5)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from evaluate) (1.21.6)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2.28.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from evaluate) (23.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from evaluate) (4.64.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (2023.1.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from evaluate) (4.11.4)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.13.3)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from evaluate) (3.2.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from evaluate) (0.3.6)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (5.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->evaluate) (2.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->evaluate) (3.11.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->evaluate) (2023.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.13.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.16.0)\nInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from rouge_score) (1.21.6)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=8d9cd43fe35506cf7d516bd9dad8a84452046352250abfc274678d11310b0877\n  Stored in directory: /root/.cache/pip/wheels/8e/6b/70/59daa7c90a238610e34bac5916e001fe3d9bb0ec59c8cf5518\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nfrom nltk.translate.bleu_score import corpus_bleu\nfrom nltk.translate.bleu_score import SmoothingFunction\nfrom nltk.translate import bleu_score\nfrom rouge import Rouge\nimport math","metadata":{"execution":{"iopub.status.busy":"2023-05-03T04:15:54.796462Z","iopub.execute_input":"2023-05-03T04:15:54.796898Z","iopub.status.idle":"2023-05-03T04:15:55.685613Z","shell.execute_reply.started":"2023-05-03T04:15:54.796857Z","shell.execute_reply":"2023-05-03T04:15:55.684515Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Calculate the BLEU score\nreferences = [[nltk.word_tokenize(original)] for original in paraphrases]\nhypotheses = [nltk.word_tokenize(predicted) for predicted in predicted]\nbleu1 = corpus_bleu(references, hypotheses, weights=(1.0, 0.0, 0.0, 0.0), smoothing_function=SmoothingFunction().method1)\nbleu2 = corpus_bleu(references, hypotheses, weights=(0.5, 0.5, 0.0, 0.0), smoothing_function=SmoothingFunction().method1)\nbleu3 = corpus_bleu(references, hypotheses, weights=(0.33, 0.33, 0.33, 0.0), smoothing_function=SmoothingFunction().method1)\nbleu4 = corpus_bleu(references, hypotheses, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=SmoothingFunction().method1)\n\nprint(\"BLEU-1 score:\", bleu1)\nprint(\"BLEU-2 score:\", bleu2)\nprint(\"BLEU-3 score:\", bleu3)\nprint(\"BLEU-4 score:\", bleu4)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T04:15:55.687298Z","iopub.execute_input":"2023-05-03T04:15:55.687755Z","iopub.status.idle":"2023-05-03T04:15:56.322326Z","shell.execute_reply.started":"2023-05-03T04:15:55.687692Z","shell.execute_reply":"2023-05-03T04:15:56.321103Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"BLEU-1 score: 0.350974245497572\nBLEU-2 score: 0.22274184876904765\nBLEU-3 score: 0.16572128548972753\nBLEU-4 score: 0.12236243282323102\n","output_type":"stream"}]},{"cell_type":"code","source":"# Calculate the Rouge score\nrouge = Rouge()\nscores = rouge.get_scores(predicted,paraphrases, avg=True)\nrouge_l = scores['rouge-l']\nprint(\"Rouge-L score:\", rouge_l)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T04:15:56.323881Z","iopub.execute_input":"2023-05-03T04:15:56.324464Z","iopub.status.idle":"2023-05-03T04:15:56.883909Z","shell.execute_reply.started":"2023-05-03T04:15:56.324423Z","shell.execute_reply":"2023-05-03T04:15:56.882597Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Rouge-L score: {'r': 0.23821037256994373, 'p': 0.16237567829684374, 'f': 0.18649049955387784}\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\nrouge = evaluate.load('rouge')\n\nresults = rouge.compute(predictions=predicted,references=paraphrases)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T04:15:56.885699Z","iopub.execute_input":"2023-05-03T04:15:56.886494Z","iopub.status.idle":"2023-05-03T04:16:00.636681Z","shell.execute_reply.started":"2023-05-03T04:15:56.886448Z","shell.execute_reply":"2023-05-03T04:16:00.635639Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dc88f94cbc946779caf346bfa116121"}},"metadata":{}}]},{"cell_type":"code","source":"results","metadata":{"execution":{"iopub.status.busy":"2023-05-03T04:16:00.638678Z","iopub.execute_input":"2023-05-03T04:16:00.639086Z","iopub.status.idle":"2023-05-03T04:16:00.645974Z","shell.execute_reply.started":"2023-05-03T04:16:00.639043Z","shell.execute_reply":"2023-05-03T04:16:00.644934Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"{'rouge1': 0.3104217595878448,\n 'rouge2': 0.061308853321295494,\n 'rougeL': 0.22275535612141933,\n 'rougeLsum': 0.2654026504245174}"},"metadata":{}}]},{"cell_type":"code","source":"bleu = evaluate.load(\"bleu\")\nresults = bleu.compute(predictions=predicted,references=paraphrases)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T04:16:00.647947Z","iopub.execute_input":"2023-05-03T04:16:00.648816Z","iopub.status.idle":"2023-05-03T04:16:01.684270Z","shell.execute_reply.started":"2023-05-03T04:16:00.648770Z","shell.execute_reply":"2023-05-03T04:16:01.683060Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe4041756cb144dcafa1cfc4dbcbd5da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5b4aa6648c3400dbb2272a72e4f9605"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67298cadf9104cd4bb26dbd9a539a167"}},"metadata":{}},{"name":"stdout","text":"{'bleu': 0.1198906550428277, 'precisions': [0.3419232417212463, 0.1382179447376591, 0.08536508536508537, 0.05121155936321207], 'brevity_penalty': 1.0, 'length_ratio': 1.2314012210748473, 'translation_length': 16337, 'reference_length': 13267}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}